{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d0fc09-636a-4755-b2a1-23891fb6f14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign', 'malignant']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "path = r'C:\\Users\\gomes\\OneDrive\\Desktop\\skin cancer prediction\\train'\n",
    "directory_contents = os.listdir(path)\n",
    "print(directory_contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1dd4a1f-be61-40bb-8cef-1648f7e513be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437\n",
      "1197\n"
     ]
    }
   ],
   "source": [
    "benign_folder = os.path.join(path,'benign')\n",
    "malignant_folder = os.path.join(path,'malignant')\n",
    "benign_contents = os.listdir(benign_folder)\n",
    "malignant_contents = os.listdir(malignant_folder)\n",
    "print(len(benign_contents))\n",
    "print(len(malignant_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce170529-1fdd-430e-a2b9-e0640b6dbbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03cba62-5ef3-462a-9efc-2ebf2f90dc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.067323</td>\n",
       "      <td>0.056441</td>\n",
       "      <td>0.135085</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.147381</td>\n",
       "      <td>0.097736</td>\n",
       "      <td>0.081393</td>\n",
       "      <td>0.086077</td>\n",
       "      <td>0.136221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058534</td>\n",
       "      <td>0.079779</td>\n",
       "      <td>0.062380</td>\n",
       "      <td>0.106386</td>\n",
       "      <td>0.117566</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.094846</td>\n",
       "      <td>0.092415</td>\n",
       "      <td>0.105509</td>\n",
       "      <td>0.162269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062301</td>\n",
       "      <td>0.077089</td>\n",
       "      <td>0.066307</td>\n",
       "      <td>0.095444</td>\n",
       "      <td>0.145687</td>\n",
       "      <td>0.114876</td>\n",
       "      <td>0.086775</td>\n",
       "      <td>0.086874</td>\n",
       "      <td>0.107601</td>\n",
       "      <td>0.157047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051279</td>\n",
       "      <td>0.076491</td>\n",
       "      <td>0.057079</td>\n",
       "      <td>0.102419</td>\n",
       "      <td>0.114019</td>\n",
       "      <td>0.126036</td>\n",
       "      <td>0.095564</td>\n",
       "      <td>0.092953</td>\n",
       "      <td>0.114178</td>\n",
       "      <td>0.169982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060387</td>\n",
       "      <td>0.082250</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.124940</td>\n",
       "      <td>0.120097</td>\n",
       "      <td>0.091418</td>\n",
       "      <td>0.088329</td>\n",
       "      <td>0.104412</td>\n",
       "      <td>0.162588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.038843  0.067323  0.056441  0.135085  0.153500  0.147381  0.097736   \n",
       "1  0.058534  0.079779  0.062380  0.106386  0.117566  0.120316  0.094846   \n",
       "2  0.062301  0.077089  0.066307  0.095444  0.145687  0.114876  0.086775   \n",
       "3  0.051279  0.076491  0.057079  0.102419  0.114019  0.126036  0.095564   \n",
       "4  0.060387  0.082250  0.065131  0.100446  0.124940  0.120097  0.091418   \n",
       "\n",
       "          7         8         9  label  \n",
       "0  0.081393  0.086077  0.136221      0  \n",
       "1  0.092415  0.105509  0.162269      0  \n",
       "2  0.086874  0.107601  0.157047      0  \n",
       "3  0.092953  0.114178  0.169982      0  \n",
       "4  0.088329  0.104412  0.162588      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radius = 1  # Radius of the circle\n",
    "n_points = 8 * radius  # Number of points in the LBP pattern\n",
    "\n",
    "# Function to extract LBP features from an image\n",
    "def extract_lbp_features(image_path, size=(224, 224), radius=1, n_points=8):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Resize the image\n",
    "    image = cv2.resize(image, size)\n",
    "    \n",
    "    # Apply LBP\n",
    "    lbp = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Flatten the LBP features into a vector\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    \n",
    "    # Normalize the histogram\n",
    "    lbp_hist = lbp_hist.astype(\"float\")\n",
    "    lbp_hist /= (lbp_hist.sum() + 1e-6)  # Normalize to make features comparable\n",
    "    \n",
    "    return lbp_hist\n",
    "\n",
    "# Define the paths to the benign and malignant folders\n",
    "\n",
    "\n",
    "# Initialize lists to hold the image data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Process benign images\n",
    "benign_images = [img for img in os.listdir(benign_folder) if img.endswith(('.jpg', '.png'))]\n",
    "for img in benign_images:\n",
    "    img_path = os.path.join(benign_folder, img)\n",
    "    features = extract_lbp_features(img_path, radius=radius, n_points=n_points)\n",
    "    data.append(features)\n",
    "    labels.append(0)  # Label for benign\n",
    "\n",
    "# Process malignant images\n",
    "malignant_images = [img for img in os.listdir(malignant_folder) if img.endswith(('.jpg', '.png'))]\n",
    "for img in malignant_images:\n",
    "    img_path = os.path.join(malignant_folder, img)\n",
    "    features = extract_lbp_features(img_path, radius=radius, n_points=n_points)\n",
    "    data.append(features)\n",
    "    labels.append(1)  # Label for malignant\n",
    "\n",
    "# Convert the data and labels into a pandas DataFrame\n",
    "df1 = pd.DataFrame(data)\n",
    "df1['label'] = labels  # Add the labels as the target column\n",
    "\n",
    "# Show the structure of the dataset\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b9ea92-812f-4bf9-86b7-8956770f5610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>26245</th>\n",
       "      <th>26246</th>\n",
       "      <th>26247</th>\n",
       "      <th>26248</th>\n",
       "      <th>26249</th>\n",
       "      <th>26250</th>\n",
       "      <th>26251</th>\n",
       "      <th>26252</th>\n",
       "      <th>26253</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038843</td>\n",
       "      <td>0.067323</td>\n",
       "      <td>0.056441</td>\n",
       "      <td>0.135085</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.147381</td>\n",
       "      <td>0.097736</td>\n",
       "      <td>0.081393</td>\n",
       "      <td>0.086077</td>\n",
       "      <td>0.136221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209080</td>\n",
       "      <td>0.055502</td>\n",
       "      <td>0.053021</td>\n",
       "      <td>0.159992</td>\n",
       "      <td>0.253187</td>\n",
       "      <td>0.166946</td>\n",
       "      <td>0.066090</td>\n",
       "      <td>0.045677</td>\n",
       "      <td>0.099831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058534</td>\n",
       "      <td>0.079779</td>\n",
       "      <td>0.062380</td>\n",
       "      <td>0.106386</td>\n",
       "      <td>0.117566</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.094846</td>\n",
       "      <td>0.092415</td>\n",
       "      <td>0.105509</td>\n",
       "      <td>0.162269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.050033</td>\n",
       "      <td>0.030081</td>\n",
       "      <td>0.324138</td>\n",
       "      <td>0.440202</td>\n",
       "      <td>0.452316</td>\n",
       "      <td>0.012327</td>\n",
       "      <td>0.020235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062301</td>\n",
       "      <td>0.077089</td>\n",
       "      <td>0.066307</td>\n",
       "      <td>0.095444</td>\n",
       "      <td>0.145687</td>\n",
       "      <td>0.114876</td>\n",
       "      <td>0.086775</td>\n",
       "      <td>0.086874</td>\n",
       "      <td>0.107601</td>\n",
       "      <td>0.157047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045968</td>\n",
       "      <td>0.015845</td>\n",
       "      <td>0.037692</td>\n",
       "      <td>0.034202</td>\n",
       "      <td>0.139967</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.040935</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.040656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051279</td>\n",
       "      <td>0.076491</td>\n",
       "      <td>0.057079</td>\n",
       "      <td>0.102419</td>\n",
       "      <td>0.114019</td>\n",
       "      <td>0.126036</td>\n",
       "      <td>0.095564</td>\n",
       "      <td>0.092953</td>\n",
       "      <td>0.114178</td>\n",
       "      <td>0.169982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225249</td>\n",
       "      <td>0.168384</td>\n",
       "      <td>0.225249</td>\n",
       "      <td>0.166123</td>\n",
       "      <td>0.225249</td>\n",
       "      <td>0.120182</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.167957</td>\n",
       "      <td>0.133703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060387</td>\n",
       "      <td>0.082250</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.124940</td>\n",
       "      <td>0.120097</td>\n",
       "      <td>0.091418</td>\n",
       "      <td>0.088329</td>\n",
       "      <td>0.104412</td>\n",
       "      <td>0.162588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196417</td>\n",
       "      <td>0.177307</td>\n",
       "      <td>0.145089</td>\n",
       "      <td>0.098221</td>\n",
       "      <td>0.165395</td>\n",
       "      <td>0.073855</td>\n",
       "      <td>0.195777</td>\n",
       "      <td>0.122990</td>\n",
       "      <td>0.094538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.038843  0.067323  0.056441  0.135085  0.153500  0.147381  0.097736   \n",
       "1  0.058534  0.079779  0.062380  0.106386  0.117566  0.120316  0.094846   \n",
       "2  0.062301  0.077089  0.066307  0.095444  0.145687  0.114876  0.086775   \n",
       "3  0.051279  0.076491  0.057079  0.102419  0.114019  0.126036  0.095564   \n",
       "4  0.060387  0.082250  0.065131  0.100446  0.124940  0.120097  0.091418   \n",
       "\n",
       "          7         8         9  ...     26245     26246     26247     26248  \\\n",
       "0  0.081393  0.086077  0.136221  ...  0.209080  0.055502  0.053021  0.159992   \n",
       "1  0.092415  0.105509  0.162269  ...  0.044372  0.004885  0.050033  0.030081   \n",
       "2  0.086874  0.107601  0.157047  ...  0.045968  0.015845  0.037692  0.034202   \n",
       "3  0.092953  0.114178  0.169982  ...  0.225249  0.168384  0.225249  0.166123   \n",
       "4  0.088329  0.104412  0.162588  ...  0.196417  0.177307  0.145089  0.098221   \n",
       "\n",
       "      26249     26250     26251     26252     26253  label  \n",
       "0  0.253187  0.166946  0.066090  0.045677  0.099831      0  \n",
       "1  0.324138  0.440202  0.452316  0.012327  0.020235      0  \n",
       "2  0.139967  0.006029  0.040935  0.011050  0.040656      0  \n",
       "3  0.225249  0.120182  0.096582  0.167957  0.133703      0  \n",
       "4  0.165395  0.073855  0.195777  0.122990  0.094538      0  \n",
       "\n",
       "[5 rows x 26255 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "block_norm = 'L2-Hys'\n",
    "\n",
    "# Function to extract HOG features from an image\n",
    "def extract_hog_features(image_path, size=(224, 224)):\n",
    "    # Read the image and convert to grayscale\n",
    "    image = imread(image_path)\n",
    "    gray_image = rgb2gray(image)\n",
    "    \n",
    "    # Resize the image\n",
    "    gray_image = cv2.resize(gray_image, size)\n",
    "    \n",
    "    # Extract HOG features\n",
    "    features, hog_image = hog(gray_image, pixels_per_cell=pixels_per_cell, \n",
    "                              cells_per_block=cells_per_block, \n",
    "                              block_norm=block_norm, \n",
    "                              visualize=True\n",
    "                           )\n",
    "    \n",
    "    # Normalize the HOG features\n",
    "    features = np.reshape(features, (-1,))\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "# Initialize lists to hold the image data and labels\n",
    "data2 = []\n",
    "labels2 = []\n",
    "\n",
    "# Process benign images\n",
    "benign_images = [img for img in os.listdir(benign_folder) if img.endswith(('.jpg', '.png'))]\n",
    "for img in benign_images:\n",
    "    img_path = os.path.join(benign_folder, img)\n",
    "    lbp_features = extract_lbp_features(img_path)\n",
    "    hog_features = extract_hog_features(img_path)\n",
    "    features = np.concatenate([lbp_features, hog_features])\n",
    "    data2.append(features)\n",
    "    labels2.append(0)  # Label for benign\n",
    "\n",
    "# Process malignant images\n",
    "malignant_images = [img for img in os.listdir(malignant_folder) if img.endswith(('.jpg', '.png'))]\n",
    "for img in malignant_images:\n",
    "    img_path = os.path.join(malignant_folder, img)\n",
    "    lbp_features = extract_lbp_features(img_path)\n",
    "    hog_features = extract_hog_features(img_path)\n",
    "    features = np.concatenate([lbp_features, hog_features])\n",
    "    data2.append(features)\n",
    "    labels2.append(1)  # Label for malignant\n",
    "\n",
    "# Convert the data and labels into a pandas DataFrame\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2['label'] = labels2  # Add the labels as the target column\n",
    "\n",
    "# Show the structure of the dataset\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26fb1a8-af2c-45fc-8301-4dd19eb70068",
   "metadata": {},
   "source": [
    "# LBP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e477b7-d031-4e63-9d17-ca959cfee3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 77.75%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80       433\n",
      "           1       0.76      0.75      0.75       358\n",
      "\n",
      "    accuracy                           0.78       791\n",
      "   macro avg       0.78      0.77      0.78       791\n",
      "weighted avg       0.78      0.78      0.78       791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df1.drop(columns=['label'])\n",
    "y = df1['label']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust parameters like n_estimators\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4da905e-0f32-4407-8496-ea106031ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 72.44%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77       433\n",
      "           1       0.77      0.56      0.65       358\n",
      "\n",
      "    accuracy                           0.72       791\n",
      "   macro avg       0.74      0.71      0.71       791\n",
      "weighted avg       0.73      0.72      0.72       791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df1.drop(columns=['label'])\n",
    "y = df1['label']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model = SVC(kernel = 'linear', random_state=42)  # You can adjust parameters like n_estimators\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"SVC Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce57060-e8be-479c-bbae-0f785996d967",
   "metadata": {},
   "source": [
    "# HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51124d3f-10ac-4f85-95a6-9577f194b2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 75.35%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79       433\n",
      "           1       0.77      0.65      0.70       358\n",
      "\n",
      "    accuracy                           0.75       791\n",
      "   macro avg       0.76      0.74      0.75       791\n",
      "weighted avg       0.76      0.75      0.75       791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df2.drop(columns=['label'])\n",
    "y = df2['label']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust parameters like n_estimators\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Random Forest Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b288f39-889e-4713-99a0-fabbb0f41758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 65.11%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69       433\n",
      "           1       0.62      0.58      0.60       358\n",
      "\n",
      "    accuracy                           0.65       791\n",
      "   macro avg       0.65      0.64      0.65       791\n",
      "weighted avg       0.65      0.65      0.65       791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df2.drop(columns=['label'])\n",
    "y = df2['label']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "model = SVC(kernel = 'linear', random_state=42)  # You can adjust parameters like n_estimators\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"SVC Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4596fa-180e-44db-a9e6-db64e69d7fec",
   "metadata": {},
   "source": [
    "# Combining both HOG and LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc382e5-2b5c-4fb0-af58-a092e3c7e35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\skimage\\feature\\texture.py:360: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>8151</th>\n",
       "      <th>8152</th>\n",
       "      <th>8153</th>\n",
       "      <th>8154</th>\n",
       "      <th>8155</th>\n",
       "      <th>8156</th>\n",
       "      <th>8157</th>\n",
       "      <th>8158</th>\n",
       "      <th>8159</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058793</td>\n",
       "      <td>0.073760</td>\n",
       "      <td>0.078743</td>\n",
       "      <td>0.138353</td>\n",
       "      <td>0.160635</td>\n",
       "      <td>0.131696</td>\n",
       "      <td>0.088229</td>\n",
       "      <td>0.072923</td>\n",
       "      <td>0.069017</td>\n",
       "      <td>0.127850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262337</td>\n",
       "      <td>0.349380</td>\n",
       "      <td>0.974291</td>\n",
       "      <td>0.872176</td>\n",
       "      <td>0.827230</td>\n",
       "      <td>0.640319</td>\n",
       "      <td>0.694269</td>\n",
       "      <td>0.936848</td>\n",
       "      <td>0.187591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080038</td>\n",
       "      <td>0.088030</td>\n",
       "      <td>0.082131</td>\n",
       "      <td>0.110890</td>\n",
       "      <td>0.124123</td>\n",
       "      <td>0.112444</td>\n",
       "      <td>0.084104</td>\n",
       "      <td>0.084642</td>\n",
       "      <td>0.083825</td>\n",
       "      <td>0.149773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876277</td>\n",
       "      <td>0.548747</td>\n",
       "      <td>0.143924</td>\n",
       "      <td>0.670726</td>\n",
       "      <td>0.362662</td>\n",
       "      <td>0.519012</td>\n",
       "      <td>0.541883</td>\n",
       "      <td>0.089203</td>\n",
       "      <td>0.071163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080855</td>\n",
       "      <td>0.084263</td>\n",
       "      <td>0.081015</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.146983</td>\n",
       "      <td>0.104412</td>\n",
       "      <td>0.078683</td>\n",
       "      <td>0.079939</td>\n",
       "      <td>0.089086</td>\n",
       "      <td>0.152722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890911</td>\n",
       "      <td>0.023037</td>\n",
       "      <td>0.419152</td>\n",
       "      <td>0.397640</td>\n",
       "      <td>0.589327</td>\n",
       "      <td>0.280211</td>\n",
       "      <td>0.284883</td>\n",
       "      <td>0.895165</td>\n",
       "      <td>0.952215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079859</td>\n",
       "      <td>0.086555</td>\n",
       "      <td>0.080357</td>\n",
       "      <td>0.107541</td>\n",
       "      <td>0.123864</td>\n",
       "      <td>0.113261</td>\n",
       "      <td>0.085738</td>\n",
       "      <td>0.080975</td>\n",
       "      <td>0.086794</td>\n",
       "      <td>0.155054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758861</td>\n",
       "      <td>0.155337</td>\n",
       "      <td>0.395783</td>\n",
       "      <td>0.231093</td>\n",
       "      <td>0.028636</td>\n",
       "      <td>0.877154</td>\n",
       "      <td>0.764112</td>\n",
       "      <td>0.385597</td>\n",
       "      <td>0.181252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.088349</td>\n",
       "      <td>0.080576</td>\n",
       "      <td>0.105409</td>\n",
       "      <td>0.129664</td>\n",
       "      <td>0.111009</td>\n",
       "      <td>0.081254</td>\n",
       "      <td>0.081892</td>\n",
       "      <td>0.085360</td>\n",
       "      <td>0.153480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655674</td>\n",
       "      <td>0.123435</td>\n",
       "      <td>0.119926</td>\n",
       "      <td>0.962019</td>\n",
       "      <td>0.268979</td>\n",
       "      <td>0.271085</td>\n",
       "      <td>0.392905</td>\n",
       "      <td>0.882937</td>\n",
       "      <td>0.862521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8161 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.058793  0.073760  0.078743  0.138353  0.160635  0.131696  0.088229   \n",
       "1  0.080038  0.088030  0.082131  0.110890  0.124123  0.112444  0.084104   \n",
       "2  0.080855  0.084263  0.081015  0.102041  0.146983  0.104412  0.078683   \n",
       "3  0.079859  0.086555  0.080357  0.107541  0.123864  0.113261  0.085738   \n",
       "4  0.083008  0.088349  0.080576  0.105409  0.129664  0.111009  0.081254   \n",
       "\n",
       "          7         8         9  ...      8151      8152      8153      8154  \\\n",
       "0  0.072923  0.069017  0.127850  ...  0.262337  0.349380  0.974291  0.872176   \n",
       "1  0.084642  0.083825  0.149773  ...  0.876277  0.548747  0.143924  0.670726   \n",
       "2  0.079939  0.089086  0.152722  ...  0.890911  0.023037  0.419152  0.397640   \n",
       "3  0.080975  0.086794  0.155054  ...  0.758861  0.155337  0.395783  0.231093   \n",
       "4  0.081892  0.085360  0.153480  ...  0.655674  0.123435  0.119926  0.962019   \n",
       "\n",
       "       8155      8156      8157      8158      8159  label  \n",
       "0  0.827230  0.640319  0.694269  0.936848  0.187591      0  \n",
       "1  0.362662  0.519012  0.541883  0.089203  0.071163      0  \n",
       "2  0.589327  0.280211  0.284883  0.895165  0.952215      0  \n",
       "3  0.028636  0.877154  0.764112  0.385597  0.181252      0  \n",
       "4  0.268979  0.271085  0.392905  0.882937  0.862521      0  \n",
       "\n",
       "[5 rows x 8161 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2)\n",
    "block_norm = 'L2-Hys'\n",
    "\n",
    "# Function to extract LBP features from an image\n",
    "def extract_lbp_features(image_path, radius=1, n_points=8):\n",
    "    image = imread(image_path)\n",
    "    gray_image = rgb2gray(image)\n",
    "    lbp = local_binary_pattern(gray_image, n_points, radius, method='uniform')\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, n_points + 2))\n",
    "    lbp_hist = lbp_hist.astype('float32')\n",
    "    lbp_hist /= (lbp_hist.sum() + 1e-6)\n",
    "    return lbp_hist\n",
    "\n",
    "# Function to extract HOG features from an image\n",
    "def extract_hog_features(image_path, size=(128, 128)):\n",
    "    image = imread(image_path)\n",
    "    gray_image = rgb2gray(image)\n",
    "    gray_image = cv2.resize(gray_image, size)\n",
    "    features, _ = hog(gray_image, pixels_per_cell=pixels_per_cell, \n",
    "                      cells_per_block=cells_per_block, \n",
    "                      block_norm=block_norm, \n",
    "                      visualize=True)\n",
    "    features = np.reshape(features, (-1,))\n",
    "    return features\n",
    "\n",
    "# Function to extract SHIFT features from an image\n",
    "def extract_shift_features(image_path):\n",
    "    # Dummy implementation of SHIFT features extraction\n",
    "    # Replace this with actual SHIFT feature extraction code\n",
    "    image = imread(image_path)\n",
    "    gray_image = rgb2gray(image)\n",
    "    # Example: Dummy feature vector\n",
    "    shift_features = np.random.rand(50)  # Replace with real SHIFT feature extraction\n",
    "    return shift_features\n",
    "\n",
    "# Initialize lists to hold the image data and labels\n",
    "data2 = []\n",
    "labels2 = []\n",
    "\n",
    "# Process benign images\n",
    "benign_images = [img for img in os.listdir(benign_folder) if img.endswith(('.jpg', '.png'))]\n",
    "for img in benign_images:\n",
    "    img_path = os.path.join(benign_folder, img)\n",
    "    lbp_features = extract_lbp_features(img_path)\n",
    "    hog_features = extract_hog_features(img_path)\n",
    "    shift_features = extract_shift_features(img_path)\n",
    "    features = np.concatenate([lbp_features, hog_features, shift_features])\n",
    "    data2.append(features)\n",
    "    labels2.append(0)  # Label for benign\n",
    "\n",
    "# Process malignant images\n",
    "malignant_images = [img for img in os.listdir(malignant_folder) if img.endswith(('.jpg', '.png'))]\n",
    "for img in malignant_images:\n",
    "    img_path = os.path.join(malignant_folder, img)\n",
    "    lbp_features = extract_lbp_features(img_path)\n",
    "    hog_features = extract_hog_features(img_path)\n",
    "    shift_features = extract_shift_features(img_path)\n",
    "    features = np.concatenate([lbp_features, hog_features, shift_features])\n",
    "    data2.append(features)\n",
    "    labels2.append(1)  # Label for malignant\n",
    "\n",
    "# Convert the data and labels into a pandas DataFrame\n",
    "df3 = pd.DataFrame(data2)\n",
    "df3['label'] = labels2  # Add the labels as the target column\n",
    "\n",
    "# Show the structure of the dataset\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937d4e35-40fc-4a7d-a4c4-75157f4bfce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with LBP, HOG, and SelectKBest: 0.81\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "\n",
    "# Model\n",
    "model = SVC()\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('selector', selector),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with LBP, HOG, and SelectKBest: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a31193-baa4-4b82-8753-0717a88add11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with LBP, HOG, and SelectKBest: 0.81\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "\n",
    "# Model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('selector', selector),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with LBP, HOG, and SelectKBest: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a920f66a-0a9c-494f-a8f0-b197df502894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best parameters found: {'model__max_depth': 10, 'model__n_estimators': 100, 'selector__k': 40}\n",
      "Best score found: 0.7987643513959304\n",
      "Accuracy with LBP, HOG, and SelectKBest: 0.81\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "\n",
    "# Model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('selector', selector),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Simplified hyperparameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [20, 30, 40],  # Number of features to select\n",
    "    'model__n_estimators': [100, 150],  # Number of trees in the forest\n",
    "    'model__max_depth': [None, 10],  # Maximum depth of the trees\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best score found:\", grid_search.best_score_)\n",
    "\n",
    "# Test the model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with LBP, HOG, and SelectKBest: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2e08e12-b292-4b29-b9dd-c0308d5a9406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best parameters found: {'model__C': 1, 'model__gamma': 'scale', 'model__kernel': 'linear', 'selector__k': 30}\n",
      "Best score found: 0.8025630218612675\n",
      "Accuracy with LBP, HOG, and SelectKBest: 0.78\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "\n",
    "# Model\n",
    "model = SVC()\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('selector', selector),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Simplified hyperparameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [20, 30, 40],  # Number of features to select\n",
    "    'model__C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'model__kernel': ['linear', 'rbf'],  # Kernel type\n",
    "    'model__gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf' kernel\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best score found:\", grid_search.best_score_)\n",
    "\n",
    "# Test the model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with LBP, HOG, and SelectKBest: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "700d460b-4a59-4712-8578-7425b7f99cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1703\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1703\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_abort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1609\u001b[0m, in \u001b[0;36mParallel._abort\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1608\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m-> 1609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborted \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabort_everything\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[0;32m   1610\u001b[0m     \u001b[38;5;66;03m# If the backend is managed externally we need to make sure\u001b[39;00m\n\u001b[0;32m   1611\u001b[0m     \u001b[38;5;66;03m# to leave it in a working state to allow for future jobs\u001b[39;00m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;66;03m# scheduling.\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m     ensure_ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Train the model with hyperparameter tuning\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Best parameters and score\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1711\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1709\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m detach_generator_exit:\n\u001b[1;32m-> 1711\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_terminate_and_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_remaining_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1714\u001b[0m     batched_results \u001b[38;5;241m=\u001b[39m _remaining_outputs\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1382\u001b[0m, in \u001b[0;36mParallel._terminate_and_reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_terminate_and_reset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstop_call\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calling:\n\u001b[0;32m   1383\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mstop_call()\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "\n",
    "# Model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('selector', selector),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [10, 20, 30],  # Number of features to select\n",
    "    'model__n_estimators': [100, 200],  # Number of trees in the forest\n",
    "    'model__max_depth': [None,  20, 30],  # Maximum depth of the trees\n",
    "    'model__min_samples_split': [ 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'model__min_samples_leaf': [ 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'model__bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best score found:\", grid_search.best_score_)\n",
    "\n",
    "# Test the model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with LBP, HOG, and SelectKBest: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882b8d8-7e51-4919-8007-449a46c5aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_test,y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e3080-9196-481f-be96-06551cb84323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Randomized hyperparameter grid\n",
    "param_distributions = {\n",
    "    'selector__k': [10, 20, 30, 40, 50],\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=20, cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best score found:\", random_search.best_score_)\n",
    "\n",
    "# Test the model\n",
    "y_pred = random_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with LBP, HOG, and SelectKBest: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ca8dc-8d3f-4d1b-9a54-7335e28f6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=50)\n",
    "\n",
    "# Model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('selector', selector),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'selector__k': [ 20, 30],  # Number of features to select\n",
    "    'model__n_estimators': [100, 200],  # Number of boosting rounds\n",
    "    'model__learning_rate': [0.01, 0.1],  # Step size shrinkage\n",
    "    'model__max_depth': [3, 5],  # Maximum depth of the trees\n",
    "    'model__subsample': [0.8, 1.0],  # Fraction of samples used for fitting each individual tree\n",
    "    'model__colsample_bytree': [ 1.0]  # Fraction of features used for each tree\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best score found:\", grid_search.best_score_)\n",
    "\n",
    "# Test the model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy with LBP, HOG, and XGBoost: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47520f57-f1cb-441f-a836-83eba4daed41",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
